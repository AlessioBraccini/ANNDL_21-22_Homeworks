{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NotBookBello.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"wosmpYiES81N"},"source":["import keras.layers\n","import tensorflow as tf\n","import numpy as np\n","import os\n","import random\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from datetime import datetime"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"djuarQh8a3Yd"},"source":["tfk = tf.keras\n","tfkl = tf.keras.layers\n","tfk.__version__\n","\n","# Random seed for reproducibility\n","\n","seed = 42\n","\n","random.seed(seed)\n","os.environ['PYTHONHASHSEED'] = str(seed)\n","np.random.seed(seed)\n","tf.random.set_seed(seed)\n","tf.compat.v1.set_random_seed(seed)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ICcAaxCOZ-AB","executionInfo":{"status":"ok","timestamp":1638033549576,"user_tz":-60,"elapsed":20545,"user":{"displayName":"Davide Li Calsi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjqmjyeaerNA4wkZrkJaX-T1nOePb2wR68fpakB=s64","userId":"12091574106887103664"}},"outputId":"9c4544f4-b232-4673-87c3-b8c9e3704613"},"source":["#Mount drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"GUQt-5FBa9Ic"},"source":["# Method for checkpoints save and callbacks \n","\n","def create_folders_and_callbacks(model_name):\n","\n","    exps_dir = './Challenge_CheckPoints'\n","    if not os.path.exists(exps_dir):\n","        os.makedirs(exps_dir)\n","\n","    now = datetime.now().strftime('%b%d_%H-%M-%S')\n","\n","    exp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\n","    if not os.path.exists(exp_dir):\n","        os.makedirs(exp_dir)\n","\n","    callbacks = []\n","\n","    # Model checkpoint\n","\n","    ckpt_dir = os.path.join(exp_dir, 'ckpts')\n","    if not os.path.exists(ckpt_dir):\n","        os.makedirs(ckpt_dir)\n","\n","    ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp'),\n","                                                       save_weights_only=False,      \n","                                                       save_best_only=True)         \n","    callbacks.append(ckpt_callback)\n","\n","    # Visualize Learning on Tensorboard\n","\n","    tb_dir = os.path.join(exp_dir, 'tb_logs')\n","    if not os.path.exists(tb_dir):\n","        os.makedirs(tb_dir)\n","\n","    tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir,\n","                                                 profile_batch=0,\n","                                                 histogram_freq=1) \n","    callbacks.append(tb_callback)\n","\n","    # Early Stopping\n","\n","    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n","    callbacks.append(es_callback)\n","\n","    return callbacks\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_HeMjHgzbTlu","executionInfo":{"status":"ok","timestamp":1637952871890,"user_tz":-60,"elapsed":941,"user":{"displayName":"Alessio Braccini","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11212416438685353511"}},"outputId":"6cc3cda8-c73c-47d1-9fd6-c76a1db7e359"},"source":["# Dataset folders\n","training_dir = \"/content/training\"\n","\n","split_seed = 123  # Splitting seed needed to avoid overlap in training and validation set\n","batch_size = 32\n","\n","# Custom function for gaussian noise \n","\n","def add_noise(img):\n","    # Add random noise to an image\n","    VARIABILITY = 25\n","    deviation = VARIABILITY*random.random()\n","    noise = np.random.normal(0, deviation, img.shape)\n","    img += noise\n","    np.clip(img, 0., 255.)\n","    return img\n","\n","# Data augmentation for training set\n","\n","train_data_gen = ImageDataGenerator(\n","    validation_split=0.1,\n","    rescale=1./255,\n","    shear_range=0.2,\n","    zoom_range=0.3,\n","    horizontal_flip=True,\n","    vertical_flip=True,\n","    brightness_range=(0.3, 1.7),\n","    rotation_range=180,\n","    height_shift_range=0.3,\n","    width_shift_range=0.3,\n","    fill_mode='reflect',\n","    channel_shift_range=0.5,\n","    preprocessing_function=add_noise,\n","    )\n","\n","valid_data_gen = ImageDataGenerator(\n","    rescale=1./255,\n","    validation_split=0.1,\n",")\n","\n","# Data load from directory and split in validation and training\n","\n","training_set = train_data_gen.flow_from_directory(\n","    directory=training_dir,\n","    target_size=(256, 256),\n","    color_mode='rgb',\n","    classes=None,\n","    batch_size=batch_size,\n","    shuffle=True,\n","    subset='training',\n","    seed=seed)\n","\n","validation_set = valid_data_gen.flow_from_directory(\n","    directory=training_dir,\n","    target_size=(256, 256),\n","    color_mode='rgb',\n","    classes=None,\n","    batch_size=batch_size,\n","    shuffle=True,\n","    subset='validation',\n","    seed=seed)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 15963 images belonging to 14 classes.\n","Found 1765 images belonging to 14 classes.\n"]}]},{"cell_type":"code","metadata":{"id":"PV0lubeQGOt3"},"source":["# Custom model made with only maxpoolings and convolutions, also add some regularization in order to acheive better performances\n","# There is a batch normalization after each convolution and before the relu\n","# There is a dropout layer after every maxpooling with 0.2\n","\n","epochs = 150\n","input_shape = (256, 256, 3)\n","\n","def build_model(input_shape):\n","\n","    #input layer of the CNN\n","    input_layer = tfkl.Input(shape=input_shape, name='Input')\n","\n","\n","    # Convolutional part, increase the number of filter (32, 64, 64, 128, 128)\n","    conv1 = tfkl.Conv2D(\n","        filters=32,\n","        kernel_size=(3, 3),\n","        strides=(1, 1),\n","        padding='same',\n","        kernel_initializer='he_uniform'\n","    )(input_layer)\n","\n","    bn1 = tfkl.BatchNormalization()(conv1)\n","\n","    relu1 = tfkl.Activation('relu')(bn1)\n","\n","    pool1 = tfkl.MaxPooling2D(\n","        pool_size=2,\n","        strides=3\n","    )(relu1)\n","\n","    dp1 = tfkl.Dropout(0.2)(pool1)\n","\n","    conv2 = tfkl.Conv2D(\n","        filters=64,\n","        kernel_size=(3, 3),\n","        strides=(1, 1),\n","        padding='same',\n","        kernel_initializer='he_uniform'\n","    )(dp1)\n","\n","    bn2 = tfkl.BatchNormalization()(conv2)\n","\n","    relu2 = tfkl.Activation('relu')(bn2)\n","\n","    conv3 = tfkl.Conv2D(\n","        filters=64,\n","        kernel_size=(3, 3),\n","        strides=(1, 1),\n","        padding='same',\n","        activation='relu',\n","        kernel_initializer='he_uniform'\n","    )(relu2)\n","\n","    bn3 = tfkl.BatchNormalization()(conv3)\n","\n","    relu3 = tfkl.Activation('relu')(bn3)\n","\n","    pool2 = tfkl.MaxPooling2D(\n","        pool_size=(2, 2),\n","        strides=2\n","    )(relu3)\n","\n","    dp2 = tfkl.Dropout(0.2)(pool2)\n","\n","    conv4 = tfkl.Conv2D(\n","        filters=128,\n","        kernel_size=(3, 3),\n","        strides=(1, 1),\n","        activation='relu',\n","        kernel_initializer='he_uniform'\n","    )(dp2)\n","\n","    bn4 = tfkl.BatchNormalization()(conv4)\n","\n","    relu4 = tfkl.Activation('relu')(bn4)\n","\n","    conv5 = tfkl.Conv2D(\n","        filters=128,\n","        kernel_size=(3, 3),\n","        strides=(1, 1),\n","        padding='same',\n","        activation='relu',\n","        kernel_initializer='he_uniform'\n","    )(relu4)\n","\n","    bn5 = tfkl.BatchNormalization()(conv5)\n","\n","    relu5 = tfkl.Activation('relu')(bn5)\n","\n","    pool3 = tfkl.MaxPooling2D(\n","        pool_size=(2, 2),\n","        strides=2\n","    )(relu5)\n","\n","    dp3 = tfkl.Dropout(0.2)(pool3)\n","\n","\n","    # Global average pooling in order to prepare data to feed the FC part\n","    global_average = tfkl.GlobalAveragePooling2D()(dp3)\n","\n","\n","    # FC part \n","    dense1 = tfkl.Dense(units=512, activation='relu', kernel_initializer='he_uniform')(global_average)\n","\n","    bn6 = tfkl.BatchNormalization()(dense1)\n","\n","    dp4 = tfkl.Dropout(0.5)(bn6)\n","\n","    output_layer = tfkl.Dense(units=14, activation='softmax', kernel_initializer='he_uniform',\n","                              name='Output')(dp4)\n","\n","    # Connect input and output through the Model class\n","    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='model')\n","\n","    # Compile the model\n","    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(1e-3), metrics='accuracy')\n","\n","    # Return the model\n","    return model\n","\n","\n","model = build_model(input_shape)\n","model.summary()\n","\n","# Create folders and callbacks\n","locals_callbacks = create_folders_and_callbacks(model_name='myCustomModel')\n","\n","\n","# Train the model\n","history = model.fit(\n","    training_set,\n","    epochs=epochs,\n","    validation_data=validation_set,\n","    callbacks=locals_callbacks\n",").history\n","\n","# Save best epoch model\n","model.save(\"ModelSave/myCustomModelSave\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NqHu_msAgA3H"},"source":["# Transfer learning with Xception\n","\n","epochs = 150\n","input_shape = (256, 256, 3)\n","\n","# Import Xception pretrained application without the FC part\n","\n","base_model = tf.keras.applications.Xception(\n","    include_top=False,\n","    weights=\"imagenet\",\n","    input_tensor=None,\n","    input_shape=input_shape,\n","    pooling=None,\n",")\n","\n","# Freeze every layer in the net\n","base_model.trainable = False\n","\n","def build_model(input_shape):\n","\n","    # Use the xception feature extraction part\n","    x = base_model.output\n","    \n","    #Build a custom FC part\n","    global_average = tfkl.GlobalAveragePooling2D()(x)\n","    \n","    dense1 = tfkl.Dense(units=1024, activation='relu', kernel_initializer='he_uniform')(global_average)\n","\n","    bn6 = tfkl.BatchNormalization()(dense1)\n","\n","    dp4 = tfkl.Dropout(0.5)(bn6)\n","\n","    output_layer = tfkl.Dense(units=14, activation='softmax', kernel_initializer='he_uniform',\n","                              name='Output')(dp4)\n","\n","    # Connect input and output through the Model class\n","    model = tfk.Model(inputs=base_model.input, outputs=output_layer, name='model')\n","\n","    # Compile the model\n","    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(1e-3), metrics='accuracy')\n","\n","    # Return the model\n","    return model\n","\n","\n","model = build_model(input_shape)\n","model.summary() \n","    \n","    \n","# Create folders and callbacks and fit\n","locals_callbacks = create_folders_and_callbacks(model_name='transferXception')\n","\n","\n","# Train the model\n","history = model.fit(\n","\ttraining_set,\n","\tepochs=epochs,\n","\tvalidation_data=validation_set,\n","\tcallbacks=locals_callbacks\n",").history\n","\n","# Fine tuning part\n","\n","# Unfreez s number of layer in the Xception\n","for layer in model.layers[:15]:\n","    layer.trainable = False\n","for layer in model.layers[15:]:\n","    layer.trainable = True\n","\n","# Recompile the model with very low learning rate\n","model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(1e-5), metrics='accuracy')\n","\n","# Callbacks\n","locals_callbacks1 = create_folders_and_callbacks(model_name='transferXception1')\n","\n","# Retrain the model\n","history = model.fit(\n","\ttraining_set,\n","\tepochs=epochs,\n","\tvalidation_data=validation_set,\n","\tcallbacks=locals_callbacks1\n",").history\n","\n","# Save model\n","model.save(\"ModelSave/transferXceptionSave\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2FyrisX2Uzi5"},"source":["#Fine tuning of EfficientNetB2. Among all the experiments on EfficientNet's fine tuning, this one was the most promising,\n","#returning a 92.2% test accuracy in the development phase. Other worse experiments are not included here.\n","\n","#Import EfficientNetB2 architecture\n","from tensorflow.keras.applications import EfficientNetB2\n","\n","#Model's hyperparameters\n","input_shape = (256,256,3)\n","epochs=100\n","learning_rate=0.001\n","classes_count = 14\n","batch_size=64\n","training_directory='/content/drive/MyDrive/ANN_Chall/training'\n","\n","#Function passed to ImageDataGenerator to add random noise to training images\n","def add_noise(img):\n","    '''Add random noise to an image'''\n","    VARIABILITY = 25\n","    deviation = VARIABILITY*random.random()\n","    noise = np.random.normal(0, deviation, img.shape)\n","    img += noise\n","    np.clip(img, 0., 255.)\n","    return img\n","\n","#Use ImageDataGenerator to perform data augmentation and split into training and validation set.\n","#The rescale attribute in ImageDataGenerator is willingly commented because EfficientNetB2 already has \n","#a recaling layer.\n","\n","split_seed =123\n","augmenter = tfk.preprocessing.image.ImageDataGenerator(\n","    validation_split=0.1, \n","    featurewise_std_normalization=True,\n","    rotation_range=90,\n","    width_shift_range=0.6,\n","    height_shift_range=0.6,\n","    horizontal_flip=True,\n","    #rescale=1/255.,\n","    brightness_range=[0.4,0.8],\n","    zoom_range=[0.8,1.2],\n","    shear_range=0.3,\n","    preprocessing_function=add_noise\n",")\n","\n","training_set = augmenter.flow_from_directory(\n","    directory=training_directory,\n","    class_mode=\"categorical\",\n","    color_mode=\"rgb\",\n","    subset=\"training\",\n","    seed=split_seed,\n","    batch_size=batch_size,\n","    target_size=(256,256)\n","    )\n","\n","validation_set = augmenter.flow_from_directory(\n","    directory=training_directory,\n","    class_mode=\"categorical\",\n","    color_mode=\"rgb\",\n","    subset=\"validation\",\n","    seed=split_seed,\n","    batch_size=batch_size,\n","    target_size=(256,256)\n","    )\n","\n","#Initiate EfficientNetB2, but exclude the top layers. We will later replace the top layers with\n","#a 1024 units Dense layer\n","effnet = EfficientNetB2(weights='imagenet',input_shape=input_shape, include_top=False)\n","\n","#\"Freeze\" every layer of EfficientNetB2 except for the last 30\n","for layer in effnet.layers[:-30]:\n","    layer.trainable=False\n","for i, layer in enumerate(effnet.layers):\n","    print(i, layer.name, layer.trainable)\n","\n","#Build the entire model by adding GlobalAveragePooling, a Dense layer with l2 regularization, a Dropout layer and an output layer \n","pooling = tfkl.GlobalAveragePooling2D()(effnet.output)\n","dense = tfkl.Dense(units=1024, activation='relu', kernel_regularizer=tfk.regularizers.l2(0.001))(pooling)\n","drop = tfkl.Dropout(0.4)(dense) # Dropout layer to reduce overfitting\n","output = tfkl.Dense(classes_count, activation='softmax')(drop) # Softmax for multiclass\n","transfer_model = tfk.models.Model(effnet.input, outputs=output)\n","\n","transfer_model.summary()\n","\n","#Create two callbacks\n","\n","from keras.callbacks import ReduceLROnPlateau\n","\n","#This one redices the learning rate when the validation accuracy is at a plateau\n","lr_reduce = ReduceLROnPlateau(monitor='val_accuracy', factor=0.6, patience=8, verbose=1, mode='max', min_lr=5e-5)\n","\n","#\"Classical\" early stop with restoring of best weights\n","early_stop = tfk.callbacks.EarlyStopping(monitor='val_loss', mode='min',patience=5, restore_best_weights=True)\n","\n","#Compile the model. We used Adam as optimizer.\n","transfer_model.compile(optimizer=tfk.optimizers.Adam(learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","#Train for 100 epochs\n","transfer_model.fit(training_set, validation_data=validation_set , callbacks = [early_stop,lr_reduce], epochs=100, batch_size=batch_size)\n","\n","tfk.models.save_model(transfer_model, './')\n"],"execution_count":null,"outputs":[]}]}